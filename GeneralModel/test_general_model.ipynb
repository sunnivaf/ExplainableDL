{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyxdf\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "\n",
    "# EEGNet-specific imports\n",
    "from EEGModels import EEGNet\n",
    "import tensorflow\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# PyRiemann imports\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "#Sklearn imports\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyriemann.utils.viz import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading EEG data\n",
    "samples = 1233\n",
    "\n",
    "X_train_01 = np.loadtxt(\"Full_data_X_P01_5.csv\")\n",
    "X_train_02 = np.loadtxt(\"Full_data_X_P02_5.csv\")\n",
    "X_train_03 = np.loadtxt(\"Full_data_X_P03_5.csv\")\n",
    "X_train_04 = np.loadtxt(\"Full_data_X_P04_5.csv\")\n",
    "X_train_05 = np.loadtxt(\"Full_data_X_P05_5.csv\")\n",
    "X_train_06 = np.loadtxt(\"Full_data_X_P06_5.csv\")\n",
    "X_train_07 = np.loadtxt(\"Full_data_X_P07_5.csv\")\n",
    "X_train_08 = np.loadtxt(\"Full_data_X_P08_5.csv\")\n",
    "X_train_09 = np.loadtxt(\"Full_data_X_P09_5.csv\")\n",
    "X_train_10 = np.loadtxt(\"Full_data_X_P10_5.csv\")\n",
    "X_train_11 = np.loadtxt(\"Full_data_X_P11_5.csv\")\n",
    "X_train_12 = np.loadtxt(\"Full_data_X_P12_5.csv\")\n",
    "X_train_13 = np.loadtxt(\"Full_data_X_P13_5.csv\")\n",
    "X_train_14 = np.loadtxt(\"Full_data_X_P14_5.csv\")\n",
    "X_train_15 = np.loadtxt(\"Full_data_X_P15_5.csv\")\n",
    "X_train_16 = np.loadtxt(\"Full_data_X_P16_5.csv\")\n",
    "X_train_17 = np.loadtxt(\"Full_data_X_P17_5.csv\")\n",
    "X_train_18 = np.loadtxt(\"Full_data_X_P18_5.csv\")\n",
    "X_train_19 = np.loadtxt(\"Full_data_X_P19_5.csv\")\n",
    "X_train_20 = np.loadtxt(\"Full_data_X_P20_5.csv\")\n",
    "\n",
    "#Reshaping\n",
    "X_train_01 = X_train_01.reshape(\n",
    "     X_train_01.shape[0], X_train_01.shape[1] // samples, samples)\n",
    "\n",
    "X_train_02 = X_train_02.reshape(\n",
    "     X_train_02.shape[0], X_train_02.shape[1] // samples, samples)\n",
    "\n",
    "X_train_03 = X_train_03.reshape(\n",
    "     X_train_03.shape[0], X_train_03.shape[1] // samples, samples)\n",
    "\n",
    "X_train_04 = X_train_04.reshape(\n",
    "     X_train_04.shape[0], X_train_04.shape[1] // samples, samples)\n",
    "\n",
    "X_train_05 = X_train_05.reshape(\n",
    "     X_train_05.shape[0], X_train_05.shape[1] // samples, samples)\n",
    "\n",
    "X_train_06 = X_train_06.reshape(\n",
    "     X_train_06.shape[0], X_train_06.shape[1] // samples, samples)\n",
    "\n",
    "X_train_07 = X_train_07.reshape(\n",
    "     X_train_07.shape[0], X_train_07.shape[1] // samples, samples)\n",
    "\n",
    "X_train_08 = X_train_08.reshape(\n",
    "     X_train_08.shape[0], X_train_08.shape[1] // samples, samples)\n",
    "\n",
    "X_train_09 = X_train_09.reshape(\n",
    "     X_train_09.shape[0], X_train_09.shape[1] // samples, samples)\n",
    "\n",
    "X_train_10 = X_train_10.reshape(\n",
    "     X_train_10.shape[0], X_train_10.shape[1] // samples, samples)\n",
    "\n",
    "X_train_11 = X_train_11.reshape(\n",
    "     X_train_11.shape[0], X_train_11.shape[1] // samples, samples)\n",
    "\n",
    "X_train_12 = X_train_12.reshape(\n",
    "     X_train_12.shape[0], X_train_12.shape[1] // samples, samples)\n",
    "\n",
    "X_train_13 = X_train_13.reshape(\n",
    "     X_train_13.shape[0], X_train_13.shape[1] // samples, samples)\n",
    "\n",
    "X_train_14 = X_train_14.reshape(\n",
    "     X_train_14.shape[0], X_train_14.shape[1] // samples, samples)\n",
    "\n",
    "X_train_15 = X_train_15.reshape(\n",
    "     X_train_15.shape[0], X_train_15.shape[1] // samples, samples)\n",
    "\n",
    "X_train_16 = X_train_16.reshape(\n",
    "     X_train_16.shape[0], X_train_16.shape[1] // samples, samples)\n",
    "\n",
    "X_train_17 = X_train_17.reshape(\n",
    "     X_train_17.shape[0], X_train_17.shape[1] // samples, samples)\n",
    "\n",
    "X_train_18 = X_train_18.reshape(\n",
    "     X_train_18.shape[0], X_train_18.shape[1] // samples, samples)\n",
    "\n",
    "X_train_19 = X_train_19.reshape(\n",
    "     X_train_19.shape[0], X_train_19.shape[1] // samples, samples)\n",
    "\n",
    "X_train_20 = X_train_20.reshape(\n",
    "     X_train_20.shape[0], X_train_20.shape[1] // samples, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing which participants should be in the training data\n",
    "X_training = np.vstack([X_train_20, X_train_19, X_train_18, X_train_17, X_train_16, X_train_15, X_train_14, X_train_13, X_train_12, X_train_11, X_train_10, X_train_09, X_train_08, \n",
    "                        X_train_07, X_train_06, X_train_05, X_train_04, X_train_03, X_train_02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading labels\n",
    "Y_train_01 = np.loadtxt(\"Full_data_Y_P01_5.csv\")\n",
    "Y_train_02 = np.loadtxt(\"Full_data_Y_P02_5.csv\")\n",
    "Y_train_03 = np.loadtxt(\"Full_data_Y_P03_5.csv\")\n",
    "Y_train_04 = np.loadtxt(\"Full_data_Y_P04_5.csv\")\n",
    "Y_train_05 = np.loadtxt(\"Full_data_Y_P05_5.csv\")\n",
    "Y_train_06 = np.loadtxt(\"Full_data_Y_P06_5.csv\")\n",
    "Y_train_07 = np.loadtxt(\"Full_data_Y_P07_5.csv\")\n",
    "Y_train_08 = np.loadtxt(\"Full_data_Y_P08_5.csv\")\n",
    "Y_train_09 = np.loadtxt(\"Full_data_Y_P09_5.csv\")\n",
    "Y_train_10 = np.loadtxt(\"Full_data_Y_P10_5.csv\")\n",
    "Y_train_11 = np.loadtxt(\"Full_data_Y_P11_5.csv\")\n",
    "Y_train_12 = np.loadtxt(\"Full_data_Y_P12_5.csv\")\n",
    "Y_train_13 = np.loadtxt(\"Full_data_Y_P13_5.csv\")\n",
    "Y_train_14 = np.loadtxt(\"Full_data_Y_P14_5.csv\")\n",
    "Y_train_15 = np.loadtxt(\"Full_data_Y_P15_5.csv\")\n",
    "Y_train_16 = np.loadtxt(\"Full_data_Y_P16_5.csv\")\n",
    "Y_train_17 = np.loadtxt(\"Full_data_Y_P17_5.csv\")\n",
    "Y_train_18 = np.loadtxt(\"Full_data_Y_P18_5.csv\")\n",
    "Y_train_19 = np.loadtxt(\"Full_data_Y_P19_5.csv\")\n",
    "Y_train_20 = np.loadtxt(\"Full_data_Y_P20_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing which participants should be in the training data\n",
    "Y_training = np.hstack([Y_train_20, Y_train_19, Y_train_18, Y_train_17, Y_train_16, Y_train_15, Y_train_14, Y_train_13, Y_train_12, Y_train_11, Y_train_10, Y_train_09, Y_train_08, \n",
    "                        Y_train_07, Y_train_06, Y_train_05, Y_train_04, Y_train_03, Y_train_02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing which participants should be in the test data\n",
    "X_testing = np.vstack([X_train_01])\n",
    "Y_testing = np.hstack([Y_train_01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels, chans, samples = 1, 16, 1233\n",
    "\n",
    "model = EEGNet(nb_classes = 1, Chans = chans, Samples = samples, \n",
    "               dropoutRate = 0.25, kernLength = 125, F1 = 8, D = 2, F2 = 16, \n",
    "               dropoutType = 'Dropout')\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_training.reshape(X_training.shape[0], -1)).reshape(X_training.shape)\n",
    "X_test = scaler.fit_transform(X_testing.reshape(X_testing.shape[0], -1)).reshape(X_testing.shape)\n",
    "\n",
    "randomize_train = np.arange(len(X_train))\n",
    "np.random.shuffle(randomize_train)\n",
    "X_train = X_train[randomize_train]\n",
    "Y_train = Y_training[randomize_train]\n",
    "\n",
    "randomize_test = np.arange(len(X_test))\n",
    "np.random.shuffle(randomize_train)\n",
    "X_test = X_test[randomize_test]\n",
    "Y_test = Y_testing[randomize_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "X_test  = X_test.reshape(X_test.shape[0], chans, samples, kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedModel = model.fit(X_train, Y_train, batch_size = 1024, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "\n",
    "pred_val = model.predict(X_test)\n",
    "#print(\"Pred val: \", pred_val)\n",
    "pred_val = np.where(pred_val > 0.5, 1, 0)\n",
    "\n",
    "labels = [\"Non-Alcohol\", \"Alcohol\"]\n",
    "cm = confusion_matrix(Y_test, pred_val)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "tn = cm[0][0] #true negatives\n",
    "fn = cm[0][1] #false positives\n",
    "\n",
    "accuracy = score[1]\n",
    "F1_score = f1_score(y_true=Y_test, y_pred=pred_val)\n",
    "precision= precision_score(y_true=Y_test, y_pred=pred_val)\n",
    "recall = recall_score(y_true=Y_test, y_pred=pred_val)\n",
    "specificity = tn/(tn+fn)\n",
    "\n",
    "print(\"The accuracy of the model with cross validation is\", accuracy)\n",
    "print(\"The precision score of the model with cross validation is\", precision)\n",
    "print(\"The recall score of the model with cross validation is\", recall)\n",
    "print(\"The F1 score of the model with cross validation is\", F1_score)\n",
    "print(\"The specificity score of the model with cross validation is\", specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
